{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Instalação das bibliotecas necessárias </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in /opt/conda/lib/python3.7/site-packages (19.1.1)\n",
      "Requirement already satisfied: pymongo in /opt/conda/lib/python3.7/site-packages (3.8.0)\n",
      "Requirement already up-to-date: nltk in /opt/conda/lib/python3.7/site-packages (3.4.3)\n",
      "Requirement already satisfied, skipping upgrade: six in /opt/conda/lib/python3.7/site-packages (from nltk) (1.12.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (0.13.2)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (0.24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /opt/conda/lib/python3.7/site-packages (from pandas) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2011k in /opt/conda/lib/python3.7/site-packages (from pandas) (2019.1)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from pandas) (1.16.4)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.5.0->pandas) (1.12.0)\n",
      "Requirement already satisfied: sklearn in /opt/conda/lib/python3.7/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from sklearn) (0.21.2)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.3.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sklearn) (0.13.2)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.16.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install pymongo\n",
    "!pip install -U nltk\n",
    "!pip install joblib\n",
    "!pip install pandas\n",
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from joblib import dump, load\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#Download do corpus da nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Definição das funções de leitura dos dados no MongoDb</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _connect_mongo(host, port, username, password, db):\n",
    "    \"\"\" A util for making a connection to mongo \"\"\"\n",
    "\n",
    "    if username and password:\n",
    "        mongo_uri = 'mongodb://%s:%s@%s:%s/%s' % (username, password, host, port, db)\n",
    "        conn = MongoClient(mongo_uri)\n",
    "    else:\n",
    "        conn = MongoClient(host, port)\n",
    "\n",
    "\n",
    "    return conn[db]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mongo(db, collection, query={}, host='ds249824.mlab.com', port='49824', username='app', password='nodeapp01', no_id=True):\n",
    "    \"\"\" Read from Mongo and Store into DataFrame \"\"\"\n",
    "\n",
    "    # Connect to MongoDB\n",
    "    db = _connect_mongo(host=host, port=port, username=username, password=password, db=db)\n",
    "\n",
    "    # Make a query to the specific DB and Collection\n",
    "    cursor = db[collection].find(query)\n",
    "\n",
    "    # Expand the cursor and construct the DataFrame\n",
    "    df =  pd.DataFrame(list(cursor))\n",
    "\n",
    "    # Delete the _id\n",
    "    if no_id:\n",
    "        del df['_id']\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Carrega os DataSets (tweets marcados como acidente e não acidente)</h3>\n",
    "<p> Cria Dataset chamado \"acidente\", com os documentos rotulados como Sim.\n",
    "<p> Cria Dataset chamado \"nao acidente\", com os documentos rotulados como Não.\n",
    "<p> Cria Dataset chamado \"full_data\", com os documentos rotulados como todos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "acidente = read_mongo('labeling_zone','tweets',query={'label':'Sim'})\n",
    "nao_acidente = read_mongo('labeling_zone','tweets',query={'label':'Não'})\n",
    "full_data = acidente.append(nao_acidente[0:277])\n",
    "#full_data = acidente.append(nao_acidente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de documentos rotulados como \"acidente\": 277\n",
      "Total de documentos rotulados como \"Não acidente\": 1506\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>location</th>\n",
       "      <th>texto</th>\n",
       "      <th>usuario</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pt</td>\n",
       "      <td>São Paulo</td>\n",
       "      <td>As faixas foram liberadas na Rod Dom Pedro I (...</td>\n",
       "      <td>radiotransitofm</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pt</td>\n",
       "      <td>São Paulo/SP, Brasil</td>\n",
       "      <td>Um dos caminhões e a carreta tombaram no acide...</td>\n",
       "      <td>TransitoSampaSP</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pt</td>\n",
       "      <td>São Paulo</td>\n",
       "      <td>Ouvintes relatam #acidente no km 39 da rodovia...</td>\n",
       "      <td>radiotransitofm</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pt</td>\n",
       "      <td>São Paulo/SP - Brasil</td>\n",
       "      <td>13h24 - Acidente de trânsito, carro x moto, na...</td>\n",
       "      <td>BombeirosPMESP</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pt</td>\n",
       "      <td>São Paulo/SP, Brasil</td>\n",
       "      <td>Acidente de trânsito, carro x moto, na R.Pedro...</td>\n",
       "      <td>TransitoSampaSP</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang               location  \\\n",
       "0   pt              São Paulo   \n",
       "1   pt   São Paulo/SP, Brasil   \n",
       "2   pt              São Paulo   \n",
       "3   pt  São Paulo/SP - Brasil   \n",
       "4   pt   São Paulo/SP, Brasil   \n",
       "\n",
       "                                               texto          usuario label  \n",
       "0  As faixas foram liberadas na Rod Dom Pedro I (...  radiotransitofm   Sim  \n",
       "1  Um dos caminhões e a carreta tombaram no acide...  TransitoSampaSP   Sim  \n",
       "2  Ouvintes relatam #acidente no km 39 da rodovia...  radiotransitofm   Sim  \n",
       "3  13h24 - Acidente de trânsito, carro x moto, na...   BombeirosPMESP   Sim  \n",
       "4  Acidente de trânsito, carro x moto, na R.Pedro...  TransitoSampaSP   Sim  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Total de documentos rotulados como \"acidente\": ' + str(len(acidente)))\n",
    "print('Total de documentos rotulados como \"Não acidente\": ' + str(len(nao_acidente)))\n",
    "\n",
    "full_data[['lang','location','texto','usuario','label']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Aplica as funções de Pré-Processamento</h2>\n",
    "<ul> \n",
    "    <li>Remoção de Urls (regex)</li>\n",
    "    <li>Conversão para minúsculo</li>\n",
    "    <li>Tokenização</li>\n",
    "    <li>Remoção de Stop Words</li>\n",
    "    <li>Steming</li>    \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_urls(text):\n",
    "    return re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text)\n",
    "\n",
    "def to_lower(text):\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Remoção de URLs</p>\n",
    "<p>Conversão para Minúsculo</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data['texto_formatado'] = full_data['texto'].apply(lambda t: remove_urls(str(t)))\n",
    "full_data['texto_formatado'] = full_data['texto_formatado'].apply(lambda t: to_lower(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Tokenização (Conversão de frases em array de tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto_formatado</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>as faixas foram liberadas na rod dom pedro i (sp-065) no km 33, em igaratá, região do vale do pa...</td>\n",
       "      <td>[as, faixas, foram, liberadas, na, rod, dom, pedro, i, (, sp-065, ), no, km, 33, ,, em, igaratá,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>um dos caminhões e a carreta tombaram no acidente, deixando cair na pista as cargas de peças de aç</td>\n",
       "      <td>[um, dos, caminhões, e, a, carreta, tombaram, no, acidente, ,, deixando, cair, na, pista, as, ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ouvintes relatam #acidente no km 39 da rodovia dos bandeirantes, sentido sp. lentidão de 1 km.</td>\n",
       "      <td>[ouvintes, relatam, #, acidente, no, km, 39, da, rodovia, dos, bandeirantes, ,, sentido, sp., le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13h24 - acidente de trânsito, carro x moto, na rua pedro de toledo, 1651 – vila mariana. uma vít...</td>\n",
       "      <td>[13h24, -, acidente, de, trânsito, ,, carro, x, moto, ,, na, rua, pedro, de, toledo, ,, 1651, –,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>acidente de trânsito, carro x moto, na r.pedro de toledo, 1651 – vila mariana. uma vítima, masc.,</td>\n",
       "      <td>[acidente, de, trânsito, ,, carro, x, moto, ,, na, r.pedro, de, toledo, ,, 1651, –, vila, marian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bloqueio total do acesso do #rodoanel no sentido perus, pista interna, para a #imigrantes na dir...</td>\n",
       "      <td>[bloqueio, total, do, acesso, do, #, rodoanel, no, sentido, perus, ,, pista, interna, ,, para, a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                       texto_formatado  \\\n",
       "0  as faixas foram liberadas na rod dom pedro i (sp-065) no km 33, em igaratá, região do vale do pa...   \n",
       "1  um dos caminhões e a carreta tombaram no acidente, deixando cair na pista as cargas de peças de aç    \n",
       "2       ouvintes relatam #acidente no km 39 da rodovia dos bandeirantes, sentido sp. lentidão de 1 km.   \n",
       "3  13h24 - acidente de trânsito, carro x moto, na rua pedro de toledo, 1651 – vila mariana. uma vít...   \n",
       "4  acidente de trânsito, carro x moto, na r.pedro de toledo, 1651 – vila mariana. uma vítima, masc.,     \n",
       "5  bloqueio total do acesso do #rodoanel no sentido perus, pista interna, para a #imigrantes na dir...   \n",
       "\n",
       "                                                                                                tokens  \n",
       "0  [as, faixas, foram, liberadas, na, rod, dom, pedro, i, (, sp-065, ), no, km, 33, ,, em, igaratá,...  \n",
       "1  [um, dos, caminhões, e, a, carreta, tombaram, no, acidente, ,, deixando, cair, na, pista, as, ca...  \n",
       "2  [ouvintes, relatam, #, acidente, no, km, 39, da, rodovia, dos, bandeirantes, ,, sentido, sp., le...  \n",
       "3  [13h24, -, acidente, de, trânsito, ,, carro, x, moto, ,, na, rua, pedro, de, toledo, ,, 1651, –,...  \n",
       "4  [acidente, de, trânsito, ,, carro, x, moto, ,, na, r.pedro, de, toledo, ,, 1651, –, vila, marian...  \n",
       "5  [bloqueio, total, do, acesso, do, #, rodoanel, no, sentido, perus, ,, pista, interna, ,, para, a...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_colwidth = 100\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "full_data['tokens'] = full_data['texto_formatado'].apply(lambda t: tokenizer.tokenize(t))\n",
    "full_data[['texto_formatado','tokens']].head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[as, faixas, foram, liberadas, na, rod, dom, pedro, i, (, sp-065, ), no, km, 33, ,, em, igaratá,...</td>\n",
       "      <td>[faixas, liberadas, rod, dom, pedro, i, sp-065, km, 33, igaratá, região, vale, paraíba, após, gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[um, dos, caminhões, e, a, carreta, tombaram, no, acidente, ,, deixando, cair, na, pista, as, ca...</td>\n",
       "      <td>[caminhões, carreta, tombaram, acidente, deixando, cair, pista, cargas, peças, aç]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ouvintes, relatam, #, acidente, no, km, 39, da, rodovia, dos, bandeirantes, ,, sentido, sp., le...</td>\n",
       "      <td>[ouvintes, relatam, acidente, km, 39, rodovia, bandeirantes, sentido, sp., lentidão, 1, km]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[13h24, -, acidente, de, trânsito, ,, carro, x, moto, ,, na, rua, pedro, de, toledo, ,, 1651, –,...</td>\n",
       "      <td>[13h24, acidente, trânsito, carro, x, moto, rua, pedro, toledo, 1651, –, vila, mariana., vítima,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[acidente, de, trânsito, ,, carro, x, moto, ,, na, r.pedro, de, toledo, ,, 1651, –, vila, marian...</td>\n",
       "      <td>[acidente, trânsito, carro, x, moto, r.pedro, toledo, 1651, –, vila, mariana., vítima, masc.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[bloqueio, total, do, acesso, do, #, rodoanel, no, sentido, perus, ,, pista, interna, ,, para, a...</td>\n",
       "      <td>[bloqueio, total, acesso, rodoanel, sentido, perus, pista, interna, imigrantes, direção, litoral...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[ouvintes, relatam, #, acidente, no, km, 39, da, rodovia, dos, bandeirantes, ,, sent, sp., lenti...</td>\n",
       "      <td>[ouvintes, relatam, acidente, km, 39, rodovia, bandeirantes, sent, sp., lentidão, 1, km, radiotr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[capotamento, no, #, corredornortesul, sentido, santana, ,, na, altura, de, congonhas., ouvintes...</td>\n",
       "      <td>[capotamento, corredornortesul, sentido, santana, altura, congonhas., ouvintes, relatam, capotam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[capotamento, no, #, corredornortesul, sentido, santana, ,, na, altura, de, congonhas., ouvintes...</td>\n",
       "      <td>[capotamento, corredornortesul, sentido, santana, altura, congonhas., ouvintes, relatam, capotam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[capotamento, no, #, corredornortesul, sentido, santana, ,, na, altura, de, congonhas., ouvintes...</td>\n",
       "      <td>[capotamento, corredornortesul, sentido, santana, altura, congonhas., ouvintes, relatam, capotam...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                tokens  \\\n",
       "0  [as, faixas, foram, liberadas, na, rod, dom, pedro, i, (, sp-065, ), no, km, 33, ,, em, igaratá,...   \n",
       "1  [um, dos, caminhões, e, a, carreta, tombaram, no, acidente, ,, deixando, cair, na, pista, as, ca...   \n",
       "2  [ouvintes, relatam, #, acidente, no, km, 39, da, rodovia, dos, bandeirantes, ,, sentido, sp., le...   \n",
       "3  [13h24, -, acidente, de, trânsito, ,, carro, x, moto, ,, na, rua, pedro, de, toledo, ,, 1651, –,...   \n",
       "4  [acidente, de, trânsito, ,, carro, x, moto, ,, na, r.pedro, de, toledo, ,, 1651, –, vila, marian...   \n",
       "5  [bloqueio, total, do, acesso, do, #, rodoanel, no, sentido, perus, ,, pista, interna, ,, para, a...   \n",
       "6  [ouvintes, relatam, #, acidente, no, km, 39, da, rodovia, dos, bandeirantes, ,, sent, sp., lenti...   \n",
       "7  [capotamento, no, #, corredornortesul, sentido, santana, ,, na, altura, de, congonhas., ouvintes...   \n",
       "8  [capotamento, no, #, corredornortesul, sentido, santana, ,, na, altura, de, congonhas., ouvintes...   \n",
       "9  [capotamento, no, #, corredornortesul, sentido, santana, ,, na, altura, de, congonhas., ouvintes...   \n",
       "\n",
       "                                                                                                 words  \n",
       "0  [faixas, liberadas, rod, dom, pedro, i, sp-065, km, 33, igaratá, região, vale, paraíba, após, gr...  \n",
       "1                   [caminhões, carreta, tombaram, acidente, deixando, cair, pista, cargas, peças, aç]  \n",
       "2          [ouvintes, relatam, acidente, km, 39, rodovia, bandeirantes, sentido, sp., lentidão, 1, km]  \n",
       "3  [13h24, acidente, trânsito, carro, x, moto, rua, pedro, toledo, 1651, –, vila, mariana., vítima,...  \n",
       "4        [acidente, trânsito, carro, x, moto, r.pedro, toledo, 1651, –, vila, mariana., vítima, masc.]  \n",
       "5  [bloqueio, total, acesso, rodoanel, sentido, perus, pista, interna, imigrantes, direção, litoral...  \n",
       "6  [ouvintes, relatam, acidente, km, 39, rodovia, bandeirantes, sent, sp., lentidão, 1, km, radiotr...  \n",
       "7  [capotamento, corredornortesul, sentido, santana, altura, congonhas., ouvintes, relatam, capotam...  \n",
       "8  [capotamento, corredornortesul, sentido, santana, altura, congonhas., ouvintes, relatam, capotam...  \n",
       "9  [capotamento, corredornortesul, sentido, santana, altura, congonhas., ouvintes, relatam, capotam...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_stopword_list():\n",
    "    portuguese_stops = set(stopwords.words('portuguese'))\n",
    "    portuguese_stops.add('rt')\n",
    "\n",
    "    with open('punctuation.txt','r+') as punct_file:\n",
    "        puncts = punct_file.readlines()\n",
    "\n",
    "    for item in puncts:    \n",
    "        portuguese_stops.add(item.strip())\n",
    "        \n",
    "    return portuguese_stops\n",
    "\n",
    "stop_w = create_stopword_list()\n",
    "\n",
    "#aplica a remocao de stop-words\n",
    "full_data['words'] = full_data['tokens'].apply(lambda w: [word for word in w if word not in stop_w]) \n",
    "#exibe resultado intermediario\n",
    "full_data[['tokens','words']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>stem_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[faixas, liberadas, rod, dom, pedro, i, sp-065, km, 33, igaratá, região, vale, paraíba, após, gr...</td>\n",
       "      <td>[faix, liber, rod, dom, pedr, i, sp-065, km, 33, igarat, regiã, val, paraíb, após, grav, acident...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[caminhões, carreta, tombaram, acidente, deixando, cair, pista, cargas, peças, aç]</td>\n",
       "      <td>[caminhõ, carret, tomb, acident, deix, cair, pist, carg, pec, ac]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ouvintes, relatam, acidente, km, 39, rodovia, bandeirantes, sentido, sp., lentidão, 1, km]</td>\n",
       "      <td>[ouvint, relat, acident, km, 39, rodov, bandeir, sent, sp., lentidã, 1, km]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[13h24, acidente, trânsito, carro, x, moto, rua, pedro, toledo, 1651, –, vila, mariana., vítima,...</td>\n",
       "      <td>[13h24, acident, trânsit, carr, x, mot, rua, pedr, toled, 1651, –, vil, mariana., vítim, masc., ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[acidente, trânsito, carro, x, moto, r.pedro, toledo, 1651, –, vila, mariana., vítima, masc.]</td>\n",
       "      <td>[acident, trânsit, carr, x, mot, r.pedr, toled, 1651, –, vil, mariana., vítim, masc.]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                 words  \\\n",
       "0  [faixas, liberadas, rod, dom, pedro, i, sp-065, km, 33, igaratá, região, vale, paraíba, após, gr...   \n",
       "1                   [caminhões, carreta, tombaram, acidente, deixando, cair, pista, cargas, peças, aç]   \n",
       "2          [ouvintes, relatam, acidente, km, 39, rodovia, bandeirantes, sentido, sp., lentidão, 1, km]   \n",
       "3  [13h24, acidente, trânsito, carro, x, moto, rua, pedro, toledo, 1651, –, vila, mariana., vítima,...   \n",
       "4        [acidente, trânsito, carro, x, moto, r.pedro, toledo, 1651, –, vila, mariana., vítima, masc.]   \n",
       "\n",
       "                                                                                            stem_words  \n",
       "0  [faix, liber, rod, dom, pedr, i, sp-065, km, 33, igarat, regiã, val, paraíb, após, grav, acident...  \n",
       "1                                    [caminhõ, carret, tomb, acident, deix, cair, pist, carg, pec, ac]  \n",
       "2                          [ouvint, relat, acident, km, 39, rodov, bandeir, sent, sp., lentidã, 1, km]  \n",
       "3  [13h24, acident, trânsit, carr, x, mot, rua, pedr, toled, 1651, –, vil, mariana., vítim, masc., ...  \n",
       "4                [acident, trânsit, carr, x, mot, r.pedr, toled, 1651, –, vil, mariana., vítim, masc.]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemer= SnowballStemmer(language='portuguese')\n",
    "full_data['stem_words'] = full_data['words'].apply(lambda t: [stemer.stem(word) for word in t])\n",
    "full_data[['words','stem_words']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    554.000000\n",
       "mean       0.500000\n",
       "std        0.500452\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        0.500000\n",
       "75%        1.000000\n",
       "max        1.000000\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encode_label(text):\n",
    "    if text=='Sim':\n",
    "        return 1\n",
    "    elif text=='Não':\n",
    "        return 0\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "full_data['target'] = full_data['label'].apply(lambda label: encode_label(label))\n",
    "full_data['target'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(554, 1991)\n"
     ]
    }
   ],
   "source": [
    "full_data['clean_text'] = full_data['stem_words'].apply(lambda t: str(' '.join(t)))\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "X_TF = count_vect.fit_transform(full_data['clean_text'])\n",
    "print(X_TF.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_TF.toarray()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(554, 1991)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "X = tfidf_transformer.fit_transform(X_TF)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, full_data['target'], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB().fit(X_train, y_train)\n",
    "svm = svm.SVC().fit(X_train,y_train)\n",
    "tree = tree.DecisionTreeClassifier().fit(X_train,y_train)\n",
    "logr = LogisticRegression().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SVC' object has no attribute 'SVC'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-26fb6122ab64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnbc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msvmc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtreec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlogr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SVC' object has no attribute 'SVC'"
     ]
    }
   ],
   "source": [
    "nbc = MultinomialNB()\n",
    "svmc = svm.SVC()\n",
    "treec = tree.DecisionTreeClassifier()\n",
    "logr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Realiza o cross validation </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_scores = cross_val_score(nbc, X, full_data['target'], cv=5)\n",
    "svm_scores = cross_val_score(svmc, X, full_data['target'], cv=5)\n",
    "tree_scores = cross_val_score(treec, X, full_data['target'], cv=5)\n",
    "logr_scores = cross_val_score(logr, X, full_data['target'], cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.87430168 0.84593838 0.85393258 0.87078652 0.86235955]\n",
      "[0.84357542 0.84313725 0.84550562 0.84550562 0.84550562]\n",
      "[0.87988827 0.85994398 0.89325843 0.89044944 0.91011236]\n",
      "[0.87150838 0.86554622 0.85955056 0.87921348 0.86797753]\n"
     ]
    }
   ],
   "source": [
    "print(nb_scores)\n",
    "print(svm_scores)\n",
    "print(tree_scores)\n",
    "print(logr_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "def print_metrics(y_true,y_predicted):\n",
    "    acc = accuracy_score(y_test.values,y_predicted)\n",
    "    print('Acurácia: ' + str(acc))\n",
    "    #accuracy_score(y_true, y_predicted)\n",
    "    print('Matriz de Confusão:' )\n",
    "    print(confusion_matrix(y_true, y_predicted, labels=[0, 1]))\n",
    "    print('Recall')\n",
    "    print(recall_score(y_true, y_predicted, average='macro')  )\n",
    "    print('Precision')\n",
    "    print(precision_score(y_true, y_predicted, average='macro')  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes\n",
      "Acurácia: 0.825136612021858\n",
      "Matriz de Confusão:\n",
      "[[73 19]\n",
      " [13 78]]\n",
      "Recall\n",
      "0.8253105590062111\n",
      "Precision\n",
      "0.8264804603212659\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Acurácia: 0.8852459016393442\n",
      "Matriz de Confusão:\n",
      "[[80 12]\n",
      " [ 9 82]]\n",
      "Recall\n",
      "0.8853320592451027\n",
      "Precision\n",
      "0.8856084150131485\n",
      "\n",
      "\n",
      "Suport Vector Machines\n",
      "Acurácia: 0.4972677595628415\n",
      "Matriz de Confusão:\n",
      "[[ 0 92]\n",
      " [ 0 91]]\n",
      "Recall\n",
      "0.5\n",
      "Precision\n",
      "0.24863387978142076\n",
      "\n",
      "\n",
      "Logistic Regressor\n",
      "Acurácia: 0.907103825136612\n",
      "Matriz de Confusão:\n",
      "[[81 11]\n",
      " [ 6 85]]\n",
      "Recall\n",
      "0.9072503583373148\n",
      "Precision\n",
      "0.9082255747126436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('Naive Bayes')\n",
    "print_metrics(y_test,nb.predict(X_test))\n",
    "print('\\n')\n",
    "print('Decision Tree')\n",
    "print_metrics(y_test,tree.predict(X_test))\n",
    "print('\\n')\n",
    "print('Suport Vector Machines')\n",
    "print_metrics(y_test,svm.predict(X_test))\n",
    "print('\\n')\n",
    "print('Logistic Regressor')\n",
    "print_metrics(y_test,logr.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
