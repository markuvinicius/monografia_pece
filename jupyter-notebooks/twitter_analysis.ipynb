{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\n",
      "  Downloading https://files.pythonhosted.org/packages/46/dc/7fd5df840efb3e56c8b4f768793a237ec4ee59891959d6a215d63f727023/pip-19.0.1-py2.py3-none-any.whl (1.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.4MB 403kB/s \n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Found existing installation: pip 9.0.3\n",
      "    Uninstalling pip-9.0.3:\n",
      "      Successfully uninstalled pip-9.0.3\n",
      "Successfully installed pip-19.0.1\n",
      "Collecting pymongo\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/45/5440555b901a8416196fbf2499c4678ef74de8080c007104107a8cfdda20/pymongo-3.7.2-cp36-cp36m-manylinux1_x86_64.whl (408kB)\n",
      "\u001b[K    100% |████████████████████████████████| 409kB 587kB/s \n",
      "\u001b[?25hInstalling collected packages: pymongo\n",
      "Successfully installed pymongo-3.7.2\n",
      "Collecting nltk\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/ed/9c755d357d33bc1931e157f537721efb5b88d2c583fe593cc09603076cc3/nltk-3.4.zip (1.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.4MB 1.6MB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: six in /opt/conda/lib/python3.6/site-packages (from nltk) (1.11.0)\n",
      "Requirement already satisfied, skipping upgrade: singledispatch in /opt/conda/lib/python3.6/site-packages (from nltk) (3.4.0.3)\n",
      "Building wheels for collected packages: nltk\n",
      "  Building wheel for nltk (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/4b/c8/24/b2343664bcceb7147efeb21c0b23703a05b23fcfeaceaa2a1e\n",
      "Successfully built nltk\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.4\n",
      "Collecting joblib\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/d9/4ea194a4c1d0148f9446054b9135f47218c23ccc6f649aeb09fab4c0925c/joblib-0.13.1-py2.py3-none-any.whl (278kB)\n",
      "\u001b[K    100% |████████████████████████████████| 286kB 1.5MB/s \n",
      "\u001b[?25hInstalling collected packages: joblib\n",
      "Successfully installed joblib-0.13.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install pymongo\n",
    "!pip install -U nltk\n",
    "!pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from joblib import dump, load\n",
    "\n",
    "#Download do corpus da nltk\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _connect_mongo(host, port, username, password, db):\n",
    "    \"\"\" A util for making a connection to mongo \"\"\"\n",
    "\n",
    "    if username and password:\n",
    "        mongo_uri = 'mongodb://%s:%s@%s:%s/%s' % (username, password, host, port, db)\n",
    "        conn = MongoClient(mongo_uri)\n",
    "    else:\n",
    "        conn = MongoClient(host, port)\n",
    "\n",
    "\n",
    "    return conn[db]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mongo(db, collection, query={}, host='ds249824.mlab.com', port='49824', username='app', password='nodeapp01', no_id=True):\n",
    "    \"\"\" Read from Mongo and Store into DataFrame \"\"\"\n",
    "\n",
    "    # Connect to MongoDB\n",
    "    db = _connect_mongo(host=host, port=port, username=username, password=password, db=db)\n",
    "\n",
    "    # Make a query to the specific DB and Collection\n",
    "    cursor = db[collection].find(query)\n",
    "\n",
    "    # Expand the cursor and construct the DataFrame\n",
    "    df =  pd.DataFrame(list(cursor))\n",
    "\n",
    "    # Delete the _id\n",
    "    if no_id:\n",
    "        del df['_id']\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>labeled_by</th>\n",
       "      <th>texto</th>\n",
       "      <th>usuario</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sun Dec 16 11:27:33 +0000 2018</td>\n",
       "      <td>1074264765747335169</td>\n",
       "      <td>Sim</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"\"\"Cidadão de bem\"\"\" confessou ter matado duas...</td>\n",
       "      <td>AIice_Costa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sat Dec 29 10:22:21 +0000 2018</td>\n",
       "      <td>1078959397752266753</td>\n",
       "      <td>Sim</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"#INFO #RDRJ temporealnews RT bandnewsfmrio: P...</td>\n",
       "      <td>TempoRealNews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fri Dec 28 10:22:18 +0000 2018</td>\n",
       "      <td>1078596997848928257</td>\n",
       "      <td>Sim</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"#RDRJ RT OperacoesRio: AV. BRASIL | BONSUCESS...</td>\n",
       "      <td>TempoRealNews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thu Dec 27 10:03:12 +0000 2018</td>\n",
       "      <td>1078229806150496256</td>\n",
       "      <td>Sim</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"#RDRJ RT OperacoesRio: CAMINHO PARA RODOVIÁRI...</td>\n",
       "      <td>TempoRealNews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sat Dec 29 09:52:11 +0000 2018</td>\n",
       "      <td>1078951805688705024</td>\n",
       "      <td>Sim</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"#RDRJ RT OperacoesRio: LINHA VERMELHA - Senti...</td>\n",
       "      <td>TempoRealNews</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             data                   id label labeled_by  \\\n",
       "0  Sun Dec 16 11:27:33 +0000 2018  1074264765747335169   Sim        NaN   \n",
       "1  Sat Dec 29 10:22:21 +0000 2018  1078959397752266753   Sim        NaN   \n",
       "2  Fri Dec 28 10:22:18 +0000 2018  1078596997848928257   Sim        NaN   \n",
       "3  Thu Dec 27 10:03:12 +0000 2018  1078229806150496256   Sim        NaN   \n",
       "4  Sat Dec 29 09:52:11 +0000 2018  1078951805688705024   Sim        NaN   \n",
       "\n",
       "                                               texto        usuario  \n",
       "0  \"\"\"Cidadão de bem\"\"\" confessou ter matado duas...    AIice_Costa  \n",
       "1  \"#INFO #RDRJ temporealnews RT bandnewsfmrio: P...  TempoRealNews  \n",
       "2  \"#RDRJ RT OperacoesRio: AV. BRASIL | BONSUCESS...  TempoRealNews  \n",
       "3  \"#RDRJ RT OperacoesRio: CAMINHO PARA RODOVIÁRI...  TempoRealNews  \n",
       "4  \"#RDRJ RT OperacoesRio: LINHA VERMELHA - Senti...  TempoRealNews  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acidente = read_mongo('labeling_zone','tweets',query={'label':'Sim'})\n",
    "nao_acidente = read_mongo('labeling_zone','tweets',query={'label':'Não'})\n",
    "full_data = acidente.append(nao_acidente[0:170])\n",
    "\n",
    "full_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_urls(text):\n",
    "    return re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text)\n",
    "\n",
    "def to_lower(text):\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data['texto_formatado'] = full_data['texto'].apply(lambda t: remove_urls(str(t)))\n",
    "full_data['texto_formatado'] = full_data['texto_formatado'].apply(lambda t: to_lower(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto_formatado</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"\"\"cidadão de bem\"\"\" confessou ter matado duas...</td>\n",
       "      <td>[``, ``, '', cidadão, de, bem, '', '', '', con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"#info #rdrj temporealnews rt bandnewsfmrio: p...</td>\n",
       "      <td>[``, #, info, #, rdrj, temporealnews, rt, band...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"#rdrj rt operacoesrio: av. brasil | bonsucess...</td>\n",
       "      <td>[``, #, rdrj, rt, operacoesrio, :, av., brasil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"#rdrj rt operacoesrio: caminho para rodoviári...</td>\n",
       "      <td>[``, #, rdrj, rt, operacoesrio, :, caminho, pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"#rdrj rt operacoesrio: linha vermelha - senti...</td>\n",
       "      <td>[``, #, rdrj, rt, operacoesrio, :, linha, verm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     texto_formatado  \\\n",
       "0  \"\"\"cidadão de bem\"\"\" confessou ter matado duas...   \n",
       "1  \"#info #rdrj temporealnews rt bandnewsfmrio: p...   \n",
       "2  \"#rdrj rt operacoesrio: av. brasil | bonsucess...   \n",
       "3  \"#rdrj rt operacoesrio: caminho para rodoviári...   \n",
       "4  \"#rdrj rt operacoesrio: linha vermelha - senti...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [``, ``, '', cidadão, de, bem, '', '', '', con...  \n",
       "1  [``, #, info, #, rdrj, temporealnews, rt, band...  \n",
       "2  [``, #, rdrj, rt, operacoesrio, :, av., brasil...  \n",
       "3  [``, #, rdrj, rt, operacoesrio, :, caminho, pa...  \n",
       "4  [``, #, rdrj, rt, operacoesrio, :, linha, verm...  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = TreebankWordTokenizer()\n",
    "full_data['tokens'] = full_data['texto_formatado'].apply(lambda t: tokenizer.tokenize(t))\n",
    "full_data[['texto_formatado','tokens']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[``, ``, '', cidadão, de, bem, '', '', '', con...</td>\n",
       "      <td>[cidadão, bem, confessou, ter, matado, duas, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[``, #, info, #, rdrj, temporealnews, rt, band...</td>\n",
       "      <td>[info, rdrj, temporealnews, bandnewsfmrio, cau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[``, #, rdrj, rt, operacoesrio, :, av., brasil...</td>\n",
       "      <td>[rdrj, operacoesrio, av., brasil, bonsucesso, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[``, #, rdrj, rt, operacoesrio, :, caminho, pa...</td>\n",
       "      <td>[rdrj, operacoesrio, caminho, rodoviária, trân...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[``, #, rdrj, rt, operacoesrio, :, linha, verm...</td>\n",
       "      <td>[rdrj, operacoesrio, linha, vermelha, sentido,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[``, #, rdrj, rt, operacoesrio, :, tanque, |, ...</td>\n",
       "      <td>[rdrj, operacoesrio, tanque, rua, cândido, ben...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[``, erro, humano, '', na, origem, do, acident...</td>\n",
       "      <td>[erro, humano, origem, acidente, elétrico, 25....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[``, gado, na, pista, provoca, acidente, '', k...</td>\n",
       "      <td>[gado, pista, provoca, acidente, kkkkkkkkkkk]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[``, jovem, perde, a, vida, em, grave, acident...</td>\n",
       "      <td>[jovem, perde, vida, grave, acidente, avenida,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[``, manu, ,, n, surta, ,, sofri, um, acidente...</td>\n",
       "      <td>[manu, n, surta, sofri, acidente, moto, quase,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  \\\n",
       "0  [``, ``, '', cidadão, de, bem, '', '', '', con...   \n",
       "1  [``, #, info, #, rdrj, temporealnews, rt, band...   \n",
       "2  [``, #, rdrj, rt, operacoesrio, :, av., brasil...   \n",
       "3  [``, #, rdrj, rt, operacoesrio, :, caminho, pa...   \n",
       "4  [``, #, rdrj, rt, operacoesrio, :, linha, verm...   \n",
       "5  [``, #, rdrj, rt, operacoesrio, :, tanque, |, ...   \n",
       "6  [``, erro, humano, '', na, origem, do, acident...   \n",
       "7  [``, gado, na, pista, provoca, acidente, '', k...   \n",
       "8  [``, jovem, perde, a, vida, em, grave, acident...   \n",
       "9  [``, manu, ,, n, surta, ,, sofri, um, acidente...   \n",
       "\n",
       "                                               words  \n",
       "0  [cidadão, bem, confessou, ter, matado, duas, t...  \n",
       "1  [info, rdrj, temporealnews, bandnewsfmrio, cau...  \n",
       "2  [rdrj, operacoesrio, av., brasil, bonsucesso, ...  \n",
       "3  [rdrj, operacoesrio, caminho, rodoviária, trân...  \n",
       "4  [rdrj, operacoesrio, linha, vermelha, sentido,...  \n",
       "5  [rdrj, operacoesrio, tanque, rua, cândido, ben...  \n",
       "6  [erro, humano, origem, acidente, elétrico, 25....  \n",
       "7      [gado, pista, provoca, acidente, kkkkkkkkkkk]  \n",
       "8  [jovem, perde, vida, grave, acidente, avenida,...  \n",
       "9  [manu, n, surta, sofri, acidente, moto, quase,...  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_stopword_list():\n",
    "    portuguese_stops = set(stopwords.words('portuguese'))\n",
    "    portuguese_stops.add('rt')\n",
    "\n",
    "    with open('punctuation.txt','r+') as punct_file:\n",
    "        puncts = punct_file.readlines()\n",
    "\n",
    "    for item in puncts:    \n",
    "        portuguese_stops.add(item.strip())\n",
    "        \n",
    "    return portuguese_stops\n",
    "\n",
    "stop_w = create_stopword_list()\n",
    "\n",
    "#aplica a remocao de stop-words\n",
    "full_data['words'] = full_data['tokens'].apply(lambda w: [word for word in w if word not in stop_w]) \n",
    "#exibe resultado intermediario\n",
    "full_data[['tokens','words']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>stem_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[cidadão, bem, confessou, ter, matado, duas, t...</td>\n",
       "      <td>[cidadã, bem, confess, ter, mat, duas, técnic,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[info, rdrj, temporealnews, bandnewsfmrio, cau...</td>\n",
       "      <td>[info, rdrj, temporealnews, bandnewsfmri, caus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[rdrj, operacoesrio, av., brasil, bonsucesso, ...</td>\n",
       "      <td>[rdrj, operacoesri, av., brasil, bonsucess, ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[rdrj, operacoesrio, caminho, rodoviária, trân...</td>\n",
       "      <td>[rdrj, operacoesri, caminh, rodoviár, trânsit,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[rdrj, operacoesrio, linha, vermelha, sentido,...</td>\n",
       "      <td>[rdrj, operacoesri, linh, vermelh, sent, centr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               words  \\\n",
       "0  [cidadão, bem, confessou, ter, matado, duas, t...   \n",
       "1  [info, rdrj, temporealnews, bandnewsfmrio, cau...   \n",
       "2  [rdrj, operacoesrio, av., brasil, bonsucesso, ...   \n",
       "3  [rdrj, operacoesrio, caminho, rodoviária, trân...   \n",
       "4  [rdrj, operacoesrio, linha, vermelha, sentido,...   \n",
       "\n",
       "                                          stem_words  \n",
       "0  [cidadã, bem, confess, ter, mat, duas, técnic,...  \n",
       "1  [info, rdrj, temporealnews, bandnewsfmri, caus...  \n",
       "2  [rdrj, operacoesri, av., brasil, bonsucess, ac...  \n",
       "3  [rdrj, operacoesri, caminh, rodoviár, trânsit,...  \n",
       "4  [rdrj, operacoesri, linh, vermelh, sent, centr...  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemer= SnowballStemmer(language='portuguese')\n",
    "full_data['stem_words'] = full_data['words'].apply(lambda t: [stemer.stem(word) for word in t])\n",
    "full_data[['words','stem_words']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    340.000000\n",
       "mean       0.500000\n",
       "std        0.500737\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        0.500000\n",
       "75%        1.000000\n",
       "max        1.000000\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encode_label(text):\n",
    "    if text=='Sim':\n",
    "        return 1\n",
    "    elif text=='Não':\n",
    "        return 0\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "full_data['target'] = full_data['label'].apply(lambda label: encode_label(label))\n",
    "full_data['target'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(340, 2050)\n"
     ]
    }
   ],
   "source": [
    "full_data['clean_text'] = full_data['stem_words'].apply(lambda t: str(' '.join(t)))\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "X_TF = count_vect.fit_transform(full_data['clean_text'])\n",
    "print(X_TF.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_TF.toarray()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(340, 2050)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "X = tfidf_transformer.fit_transform(X_TF)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, full_data['target'], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB().fit(X_train, y_train)\n",
    "svm = svm.SVC().fit(X_train,y_train)\n",
    "tree = tree.DecisionTreeClassifier().fit(X_train,y_train)\n",
    "logr = LogisticRegression().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "def print_metrics(y_true,y_predicted):\n",
    "    acc = accuracy_score(y_test.values,y_predicted)\n",
    "    print('Acurácia: ' + str(acc))\n",
    "    #accuracy_score(y_true, y_predicted)\n",
    "    print('Matriz de Confusão:' )\n",
    "    print(confusion_matrix(y_true, y_predicted, labels=[0, 1]))\n",
    "    print('Recall')\n",
    "    print(recall_score(y_true, y_predicted, average='macro')  )\n",
    "    print('Precision')\n",
    "    print(precision_score(y_true, y_predicted, average='macro')  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes\n",
      "Acurácia: 0.867256637168\n",
      "Matriz de Confusão:\n",
      "[[41 12]\n",
      " [ 3 57]]\n",
      "Recall\n",
      "0.86179245283\n",
      "Precision\n",
      "0.87895256917\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Acurácia: 0.823008849558\n",
      "Matriz de Confusão:\n",
      "[[45  8]\n",
      " [12 48]]\n",
      "Recall\n",
      "0.824528301887\n",
      "Precision\n",
      "0.823308270677\n",
      "\n",
      "\n",
      "Suport Vector Machines\n",
      "Acurácia: 0.469026548673\n",
      "Matriz de Confusão:\n",
      "[[53  0]\n",
      " [60  0]]\n",
      "Recall\n",
      "0.5\n",
      "Precision\n",
      "0.234513274336\n",
      "\n",
      "\n",
      "Logistic Regressor\n",
      "Acurácia: 0.814159292035\n",
      "Matriz de Confusão:\n",
      "[[50  3]\n",
      " [18 42]]\n",
      "Recall\n",
      "0.821698113208\n",
      "Precision\n",
      "0.83431372549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('Naive Bayes')\n",
    "print_metrics(y_test,nb.predict(X_test))\n",
    "print('\\n')\n",
    "print('Decision Tree')\n",
    "print_metrics(y_test,tree.predict(X_test))\n",
    "print('\\n')\n",
    "print('Suport Vector Machines')\n",
    "print_metrics(y_test,svm.predict(X_test))\n",
    "print('\\n')\n",
    "print('Logistic Regressor')\n",
    "print_metrics(y_test,logr.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
